{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pf-HVYEcLJ1c",
    "outputId": "e939da9a-b125-4e0d-a561-07b2c7b64e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "## For colab - you must install the GPU version of this each time\n",
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rrJ97oeTLLsd"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.cloud import storage\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard\n",
    "import datetime\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.models.resnet import *\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgg2I1vfNFX7",
    "outputId": "119fb270-678f-45fb-92b2-df5131474be8"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "os.chdir('drive/MyDrive/Colab Notebooks/AICORE/FAISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mY6sDC8LNKc7"
   },
   "outputs": [],
   "source": [
    "## Leverage the process_img function\n",
    "\n",
    "def process_img(image):\n",
    "    \"\"\"\n",
    "    Process an input image for use in the modified pretrained resnet50 classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : str\n",
    "        The file path of the input image to be processed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        A processed image represented as a PyTorch tensor with specific dimensions.\n",
    "    \"\"\"    \n",
    "    pil_to_tensor = transforms.ToTensor()\n",
    "    resize = transforms.Resize((225,225))\n",
    "    img = Image.open(image).convert('RGB')\n",
    "\n",
    "    features = pil_to_tensor(img)\n",
    "    features = resize(features)\n",
    "    features = torch.unsqueeze(features, dim=0)\n",
    "    #print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpRSrAD4OAXd",
    "outputId": "ca57569a-ff3b-4526-d521-75cbe8b6333c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Read the embeddings JSON file and convert to a dictionary\n",
    "\n",
    "with open('Faiss_API/final_embeddings_sep.json', \"r\") as json_file:\n",
    "    data_dict = json.load(json_file)\n",
    "\n",
    "index = faiss.IndexFlatL2(1000)   # build the index, d=size of vectors\n",
    "# here we assume xb contains a n-by-d numpy matrix of type float32\n",
    "\n",
    "## Create a flattened array of float32 vectors\n",
    "embeddings_array = np.array(list(data_dict.values()), dtype='float32')\n",
    "## Create a maching array of the vector ids (based on the filenames)\n",
    "embeddings_ids = np.array(list(data_dict.keys()))\n",
    "## Create the FAISS index by using the add function\n",
    "index.add(embeddings_array)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7pqGFePgOCLR"
   },
   "outputs": [],
   "source": [
    "## Created a classifier based on the RESNET50 pretrained model\n",
    "\n",
    "class ItemFeatureExtractor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A custom nn.Module class housing the classifier which is\n",
    "    based on a gpu-derived pretrained resnet50 from NVIDA torchhub\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    __init__():\n",
    "        Initialises the classifier and loads the model from the torchhub\n",
    "        unless it is able to detect a cached instance.\n",
    "        Replaces the final layer with a 13 class output\n",
    "    \n",
    "    forward():\n",
    "        Initiates the forward pass\n",
    "        \n",
    "    \"\"\"        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "        #self.resnet50 = model\n",
    "        self.resnet50.fc = torch.nn.Linear(2048,1000)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return F.softmax(self.resnet50(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5Lqph0bQzrC",
    "outputId": "37fc51c8-2e7d-4753-d0bb-bc074de35853"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "## Instantiate the model class as the feature extractor with the original parameters\n",
    "model = ItemFeatureExtractor()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "## Load the final training weights\n",
    "checkpoint = torch.load('final_weights/weights.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEIgg_7QQ2EP"
   },
   "source": [
    "# Remove the final classification layer and make a  embedding output available\n",
    "model = nn.Sequential(*list(model.resnet50.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "naWhOO8rQ4j0"
   },
   "outputs": [],
   "source": [
    "## Test FAISS by creating a set of query embeddings using the model output and process_image function\n",
    "query_embeddings = model(process_img('pytorch_images_tv/train/appliances/16.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Xj3bx5sHSopY"
   },
   "outputs": [],
   "source": [
    "## Flatten the output\n",
    "query_embeddings = query_embeddings.view(query_embeddings.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qG-0dqP_TE8i"
   },
   "outputs": [],
   "source": [
    "## Convert the output to an float 32 array\n",
    "query_vector = np.array(list(query_embeddings.tolist()), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUSraaX9TSdf",
    "outputId": "61b89547-d1f9-40de-bda5-eb27ffbd15bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4WsrFOaeTePJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Test the index search\n",
    "D, I = index.search(query_vector.reshape(1, -1), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWJSTpqpT6JD",
    "outputId": "2da0acf3-8e84-431d-9b0d-acc30c85c751"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DOfFZcvZT7Mc",
    "outputId": "a7d8371f-fd7b-467f-c5d7-005adc293292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch_images_tv/train/sportsleisure/lpi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_ids[759]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRda_VxhUklf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
