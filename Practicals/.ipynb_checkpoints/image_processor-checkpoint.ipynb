{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc84aae4-d319-4195-812f-da9e978e8c8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc84aae4-d319-4195-812f-da9e978e8c8e",
    "outputId": "1c995a81-ef02-4f86-db6b-0f58f04d0d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.cloud import storage\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard\n",
    "import datetime\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.models.resnet import *\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import json\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb58fe-50a2-409b-a26f-e5f10aa10ca1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79ygjaQUGU7b",
    "outputId": "e26c1312-047a-4446-cc49-00b22af469a8"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "os.chdir('drive/MyDrive/Colab Notebooks/AICORE/FAISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "n19F9XHNu6vZ",
   "metadata": {
    "id": "n19F9XHNu6vZ"
   },
   "outputs": [],
   "source": [
    "## Creating a train dataset class\n",
    "class ItemsTrainDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.examples = self._load_examples()\n",
    "        self.pil_to_tensor = transforms.ToTensor()\n",
    "        self.resize = transforms.Resize((225,225))\n",
    "        #self.rgbify = transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x)\n",
    "\n",
    "    def _load_examples(self):\n",
    "        class_names = os.listdir('pytorch_images_tv/train')\n",
    "        class_encoder = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "        class_decoder = {idx: class_name for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "        examples_list = []\n",
    "        for cl_name in class_names:\n",
    "            example_fp = os.listdir(os.path.join('pytorch_images_tv/train',cl_name))\n",
    "            example_fp = [os.path.join('pytorch_images_tv/train', cl_name, img_name ) for img_name in example_fp]\n",
    "            example = [(img_name, class_encoder[cl_name]) for img_name in example_fp]\n",
    "            examples_list.extend(example)\n",
    "\n",
    "        return examples_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_fp, img_class = self.examples[idx]\n",
    "        img = Image.open(img_fp)\n",
    "\n",
    "        features = self.pil_to_tensor(img)\n",
    "        features = self.resize(features)\n",
    "        #features = self.rgbify(features)\n",
    "\n",
    "        return features, img_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "W9GGJ8-Yu9Tj",
   "metadata": {
    "id": "W9GGJ8-Yu9Tj"
   },
   "outputs": [],
   "source": [
    "traindataset = ItemsTrainDataSet()\n",
    "train_loader = DataLoader(dataset = traindataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8557b33d-cb2c-4333-b8fb-e600632b6e1c",
   "metadata": {
    "id": "8557b33d-cb2c-4333-b8fb-e600632b6e1c"
   },
   "outputs": [],
   "source": [
    "def process_img(image):\n",
    "    pil_to_tensor = transforms.ToTensor()\n",
    "    resize = transforms.Resize((225,225))\n",
    "    img = Image.open(image).convert('RGB')\n",
    "\n",
    "    features = pil_to_tensor(img)\n",
    "    features = resize(features)\n",
    "    features = torch.unsqueeze(features, dim=0)\n",
    "    #print(features.shape)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "_P5_pH9zkfD7",
   "metadata": {
    "id": "_P5_pH9zkfD7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abaecdf3-a02d-48c1-87aa-2b119de268b6",
   "metadata": {
    "id": "abaecdf3-a02d-48c1-87aa-2b119de268b6"
   },
   "outputs": [],
   "source": [
    "## Created a classifier based on the RESNET50 pretrained model\n",
    "\n",
    "class ItemFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "        #self.resnet50 = model\n",
    "        self.resnet50.fc = torch.nn.Linear(2048,1000)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return F.softmax(self.resnet50(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c333a7-6725-47a7-bdc0-7a5433d8cfe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65c333a7-6725-47a7-bdc0-7a5433d8cfe2",
    "outputId": "d4e65b25-895e-4c09-baa9-4ffcac2f337e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "model = ItemFeatureExtractor()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "checkpoint = torch.load('final_weights/weights.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#epoch = checkpoint['epoch']\n",
    "#loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550acf6a-48d3-4919-9cae-609cfb0800db",
   "metadata": {
    "id": "a7fcea26-b9fa-4c87-b956-76a37c798226"
   },
   "source": [
    "## remove last layer to 2048 feature output\n",
    "model = nn.Sequential(*list(model.resnet50.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6qxsu2SZNYq6",
   "metadata": {
    "id": "6qxsu2SZNYq6"
   },
   "outputs": [],
   "source": [
    "## loop through images to get embeddings\n",
    "\n",
    "class_list = os.listdir('pytorch_images_tv/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9J-colTKN0iD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J-colTKN0iD",
    "outputId": "8c9c3702-de79-4da1-cb8f-bdefd23e9357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['homegarden', 'appliances', 'computers', 'office', 'sportsleisure', 'kidstoys', 'phones', 'healthbeauty', 'videogames', 'diytools', 'clothes', 'other', 'booksfilmmusicgames']\n"
     ]
    }
   ],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "F4tkhFh7c1ew",
   "metadata": {
    "id": "F4tkhFh7c1ew"
   },
   "outputs": [],
   "source": [
    "#####PROCESS EACH TRAINING IMAGE THROUGH THE MODEL AND WRITE EMBEDDINGS TO A DICTIONARY######\n",
    "\n",
    "images_dir = 'pytorch_images_tv/train'\n",
    "embeddings_dict = {}\n",
    "\n",
    "for cat in class_list:\n",
    "  for i in os.listdir(os.path.join(images_dir, cat)):\n",
    "    image_fp = os.path.join(images_dir, cat, i)\n",
    "    batch_embeddings = model(process_img(os.path.join(images_dir, cat, i)))\n",
    "    batch_embeddings = batch_embeddings.view(batch_embeddings.size(0), -1)\n",
    "\n",
    "    for emb, file_name in zip(batch_embeddings, image_fp):\n",
    "        # Get the image ID from the file name (assuming it is the filename without extension)\n",
    "        image_id = image_fp.split(\".\")[0]\n",
    "\n",
    "        # Create a dictionary for each embedding entry\n",
    "        embeddings_dict[image_id] = emb.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "_UOkQbhOpgA2",
   "metadata": {
    "id": "_UOkQbhOpgA2"
   },
   "outputs": [],
   "source": [
    "#### Write the embeddings dictionary to a JSON file\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = \"final_embeddings_sep.json\"\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(json_file_path, 'w') as file:\n",
    "    # Write the dictionary to the JSON file\n",
    "    json.dump(embeddings_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "MQNNwkQrTten",
   "metadata": {
    "id": "MQNNwkQrTten"
   },
   "outputs": [],
   "source": [
    "## Write the json embeddings to a final\n",
    "with open('final_embeddings_sep.json', \"r\") as json_file:\n",
    "  data_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DZA7SSEUVywZ",
   "metadata": {
    "id": "DZA7SSEUVywZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
