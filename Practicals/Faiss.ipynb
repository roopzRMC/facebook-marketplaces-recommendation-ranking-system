{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf-HVYEcLJ1c",
        "outputId": "e939da9a-b125-4e0d-a561-07b2c7b64e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "## For colab - you must install the GPU version of this each time\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from google.cloud import storage\n",
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "# %load_ext tensorboard\n",
        "import datetime\n",
        "import time\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.models.resnet import *\n",
        "from torchvision.models.resnet import BasicBlock, Bottleneck"
      ],
      "metadata": {
        "id": "rrJ97oeTLLsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('drive/MyDrive/Colab Notebooks/AICORE/FAISS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgg2I1vfNFX7",
        "outputId": "119fb270-678f-45fb-92b2-df5131474be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Leverage the process_img function\n",
        "\n",
        "def process_img(image):\n",
        "    pil_to_tensor = transforms.ToTensor()\n",
        "    resize = transforms.Resize((225,225))\n",
        "    img = Image.open(image).convert('RGB')\n",
        "\n",
        "    features = pil_to_tensor(img)\n",
        "    features = resize(features)\n",
        "    features = torch.unsqueeze(features, dim=0)\n",
        "    #print(features.shape)\n",
        "    return features"
      ],
      "metadata": {
        "id": "mY6sDC8LNKc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read the embeddings JSON file and convert to a dictionary\n",
        "\n",
        "with open('final_embeddings.json', \"r\") as json_file:\n",
        "    data_dict = json.load(json_file)\n",
        "\n",
        "index = faiss.IndexFlatL2(2048)   # build the index, d=size of vectors\n",
        "# here we assume xb contains a n-by-d numpy matrix of type float32\n",
        "\n",
        "## Create a flattened array of float32 vectors\n",
        "embeddings_array = np.array(list(data_dict.values()), dtype='float32')\n",
        "## Create a maching array of the vector ids (based on the filenames)\n",
        "embeddings_ids = np.array(list(data_dict.keys()))\n",
        "## Create the FAISS index by using the add function\n",
        "index.add(embeddings_array)\n",
        "print(index.is_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpRSrAD4OAXd",
        "outputId": "ca57569a-ff3b-4526-d521-75cbe8b6333c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Created a classifier based on the RESNET50 pretrained model\n",
        "\n",
        "class ItemFeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
        "        #self.resnet50 = model\n",
        "        self.resnet50.fc = torch.nn.Linear(2048,13)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return F.softmax(self.resnet50(X))"
      ],
      "metadata": {
        "id": "7pqGFePgOCLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Instantiate the model class as the feature extractor with the original parameters\n",
        "model = ItemFeatureExtractor()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "## Load the final training weights\n",
        "checkpoint = torch.load('final_weights/weights.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Lqph0bQzrC",
        "outputId": "37fc51c8-2e7d-4753-d0bb-bc074de35853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove the final classification layer and make a 2048 embedding output available\n",
        "model = nn.Sequential(*list(model.resnet50.children())[:-1])"
      ],
      "metadata": {
        "id": "AEIgg_7QQ2EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test FAISS by creating a set of query embeddings using the model output and process_image function\n",
        "query_embeddings = model(process_img('pytorch_images_tv/train/appliances/16.jpg'))"
      ],
      "metadata": {
        "id": "naWhOO8rQ4j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Flatten the output\n",
        "query_embeddings = query_embeddings.view(query_embeddings.size(0), -1)"
      ],
      "metadata": {
        "id": "Xj3bx5sHSopY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert the output to an float 32 array\n",
        "query_vector = np.array(list(query_embeddings.tolist()), dtype='float32')"
      ],
      "metadata": {
        "id": "qG-0dqP_TE8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUSraaX9TSdf",
        "outputId": "61b89547-d1f9-40de-bda5-eb27ffbd15bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Test the index search\n",
        "D, I = index.search(query_vector.reshape(1, -1), 4)"
      ],
      "metadata": {
        "id": "4WsrFOaeTePJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWJSTpqpT6JD",
        "outputId": "2da0acf3-8e84-431d-9b0d-acc30c85c751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[814, 942, 759, 843]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_ids[759]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DOfFZcvZT7Mc",
        "outputId": "a7d8371f-fd7b-467f-c5d7-005adc293292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pytorch_images_tv/train/appliances/11-Best-Small-Kitchen-Appliances-Banner-MJ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRda_VxhUklf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}